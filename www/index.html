<!doctype html>
<html>
  <head>
    <meta charset="UTF-8" />
    <title>Native WebGPU Morphology</title>
    <style>
      body {
        margin: 0;
        overflow: hidden;
        background: black;
      }
      #ui {
        position: fixed;
        bottom: 20px;
        left: 50%;
        transform: translateX(-50%);
        display: flex;
        gap: 10px;
      }
      button {
        padding: 10px 20px;
      }
      button.active {
        background: #2a7fff;
        color: white;
      }
    </style>
  </head>
  <body>
    <div id="ui">
      <button id="none" class="active">Original</button>
      <button id="white">White TopHat</button>
      <button id="black">Black TopHat</button>
      <button id="threshold">Threshold</button>
      <label style="display: flex; align-items: center; gap: 8px">
        <input
          id="thresholdSlider"
          type="range"
          min="0"
          max="100"
          value="50"
          style="width: 200px"
        />
        <span id="thresholdVal">50%</span>
      </label>
    </div>

    <canvas id="gpuCanvas"></canvas>

    <script type="module">
      if (!navigator.gpu) {
        alert("WebGPU not supported");
        throw "";
      }

      // ---------------- CAMERA ----------------
      const video = document.createElement("video");
      video.autoplay = true;
      video.playsInline = true;

      const stream = await navigator.mediaDevices.getUserMedia({
        video: { width: 1280, height: 720 },
      });

      video.srcObject = stream;
      await video.play();

      const width = video.videoWidth;
      const height = video.videoHeight;

      // ---------------- WEBGPU SETUP ----------------
      const adapter = await navigator.gpu.requestAdapter();
      const device = await adapter.requestDevice();

      const canvas = document.getElementById("gpuCanvas");
      canvas.width = width;
      canvas.height = height;

      const context = canvas.getContext("webgpu");
      const format = navigator.gpu.getPreferredCanvasFormat();

      context.configure({
        device,
        format,
        alphaMode: "opaque",
      });

      // External video texture
      function getVideoTexture() {
        return device.importExternalTexture({
          source: video,
        });
      }

      // Storage texture helper
      function createStorageTexture() {
        return device.createTexture({
          size: [width, height],
          format: "rgba8unorm",
          usage:
            GPUTextureUsage.STORAGE_BINDING |
            GPUTextureUsage.TEXTURE_BINDING |
            GPUTextureUsage.RENDER_ATTACHMENT,
        });
      }

      const grayTex = createStorageTexture();
      const erodeTex = createStorageTexture();
      const dilateTex = createStorageTexture();
      const tempTex = createStorageTexture();
      const resultTex = createStorageTexture();
      const thresholdTex = createStorageTexture();
      const cleanTex1 = createStorageTexture(); // for closing dilation
      const cleanTex2 = createStorageTexture(); // for closing erosion

      // threshold state and GPU buffer
      let thresholdOn = false;
      let threshold = 0;
      let thresholdDirty = true;
      const thresholdBuffer = device.createBuffer({
        size: 4,
        usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
      });

      const WORKGROUP = 8;
      const K = 3;

      // ---------------- SHADER CREATION ----------------
      function computePipeline(code) {
        return device.createComputePipeline({
          layout: "auto",
          compute: {
            module: device.createShaderModule({ code }),
            entryPoint: "main",
          },
        });
      }

      // ---------- GRAYSCALE ----------
      const grayscalePipeline = computePipeline(`
@group(0) @binding(0) var inputTex : texture_external;
@group(0) @binding(1) var outTex : texture_storage_2d<rgba8unorm, write>;

@compute @workgroup_size(${WORKGROUP},${WORKGROUP})
fn main(@builtin(global_invocation_id) id : vec3<u32>) {

  let dims = textureDimensions(outTex);
  if (id.x >= dims.x || id.y >= dims.y) { return; }

  let color = textureLoad(inputTex, vec2<i32>(id.xy));
  let g = dot(color.rgb, vec3<f32>(0.299,0.587,0.114));

  textureStore(outTex,
    vec2<i32>(id.xy),
    vec4<f32>(g,g,g,1.0));
}
`);

      // ---------- EROSION ----------
      const erosionPipeline = computePipeline(`
@group(0) @binding(0) var inputTex : texture_2d<f32>;
@group(0) @binding(1) var outTex : texture_storage_2d<rgba8unorm, write>;

@compute @workgroup_size(${WORKGROUP},${WORKGROUP})
fn main(@builtin(global_invocation_id) id : vec3<u32>) {

  let dims = textureDimensions(outTex);
  if (id.x >= dims.x || id.y >= dims.y) { return; }

  var minVal : f32 = 1.0;

  for (var y:i32=-${K}; y<=${K}; y++) {
    for (var x:i32=-${K}; x<=${K}; x++) {

      let c = vec2<i32>(id.xy) + vec2<i32>(x,y);

      if (c.x < 0 || c.y < 0 ||
          c.x >= i32(dims.x) ||
          c.y >= i32(dims.y)) {
        continue;
      }

      let v = textureLoad(inputTex, c, 0).r;
      minVal = min(minVal, v);
    }
  }

  textureStore(outTex,
    vec2<i32>(id.xy),
    vec4<f32>(minVal,minVal,minVal,1.0));
}
`);

      // ---------- DILATION ----------
      const dilationPipeline = computePipeline(`
@group(0) @binding(0) var inputTex : texture_2d<f32>;
@group(0) @binding(1) var outTex : texture_storage_2d<rgba8unorm, write>;

@compute @workgroup_size(${WORKGROUP},${WORKGROUP})
fn main(@builtin(global_invocation_id) id : vec3<u32>) {

  let dims = textureDimensions(outTex);
  if (id.x >= dims.x || id.y >= dims.y) { return; }

  var maxVal : f32 = 0.0;

  for (var y:i32=-${K}; y<=${K}; y++) {
    for (var x:i32=-${K}; x<=${K}; x++) {

      let c = vec2<i32>(id.xy) + vec2<i32>(x,y);

      if (c.x < 0 || c.y < 0 ||
          c.x >= i32(dims.x) ||
          c.y >= i32(dims.y)) {
        continue;
      }

      let v = textureLoad(inputTex, c, 0).r;
      maxVal = max(maxVal, v);
    }
  }

  textureStore(outTex,
    vec2<i32>(id.xy),
    vec4<f32>(maxVal,maxVal,maxVal,1.0));
}
`);

      // ---------- SUBTRACTION ----------
      const subtractPipeline = computePipeline(`
@group(0) @binding(0) var a : texture_2d<f32>;
@group(0) @binding(1) var b : texture_2d<f32>;
@group(0) @binding(2) var outTex : texture_storage_2d<rgba8unorm, write>;

@compute @workgroup_size(${WORKGROUP},${WORKGROUP})
fn main(@builtin(global_invocation_id) id : vec3<u32>) {
  let dims = textureDimensions(outTex);
  if (id.x >= dims.x || id.y >= dims.y) { return; }
  let av = textureLoad(a, vec2<i32>(id.xy), 0).r;
  let bv = textureLoad(b, vec2<i32>(id.xy), 0).r;
  let r = max(av - bv, 0.0);
  textureStore(outTex,
    vec2<i32>(id.xy),
    vec4<f32>(r,r,r,1.0));
}
`);

      // ---------- THRESHOLD ----------
      const thresholdPipeline = computePipeline(`
@group(0) @binding(0) var inputTex : texture_2d<f32>;
@group(0) @binding(1) var outTex : texture_storage_2d<rgba8unorm, write>;
@group(0) @binding(2) var<uniform> thresh : f32;

@compute @workgroup_size(${WORKGROUP},${WORKGROUP})
fn main(@builtin(global_invocation_id) id : vec3<u32>) {
  let dims = textureDimensions(outTex);
  if (id.x >= dims.x || id.y >= dims.y) { return; }
  let v = textureLoad(inputTex, vec2<i32>(id.xy), 0).r;
  let b = select(0.0, 1.0, v > thresh);
  textureStore(outTex, vec2<i32>(id.xy), vec4<f32>(b, b, b, 1.0));
}
`);

      // ---------- PRESENT PIPELINE ----------
      const renderPipeline = device.createRenderPipeline({
        layout: "auto",
        vertex: {
          module: device.createShaderModule({
            code: `
      @vertex
      fn main(@builtin(vertex_index) i : u32)
        -> @builtin(position) vec4<f32> {

        var pos = array<vec2<f32>,6>(
          vec2(-1,-1), vec2(1,-1), vec2(-1,1),
          vec2(-1,1),  vec2(1,-1), vec2(1,1)
        );

        return vec4(pos[i],0,1);
      }
      `,
          }),
          entryPoint: "main",
        },
        fragment: {
          module: device.createShaderModule({
            code: `
      @group(0) @binding(0) var tex : texture_2d<f32>;
      @group(0) @binding(1) var samp : sampler;

      @fragment
      fn main(@builtin(position) pos : vec4<f32>)
        -> @location(0) vec4<f32> {

        let uv = pos.xy / vec2<f32>(${width}.0, ${height}.0);
        return textureSample(tex, samp, uv);
      }
      `,
          }),
          entryPoint: "main",
          targets: [{ format }],
        },
        primitive: { topology: "triangle-list" },
      });

      const sampler = device.createSampler({
        magFilter: "nearest",
        minFilter: "nearest",
      });

      let mode = "none";

      // compute automatic threshold by reading the current resultTex.
      // This function is intentionally heavy, so we throttle to ~10Hz and
      // optionally downsample the source by skipping pixels (scale factor).
      let lastThresholdTime = 0; // ms
      async function computeAutoThreshold(scale = 2) {
        const now = performance.now();
        if (now - lastThresholdTime < 100) {
          // too soon
          return;
        }
        lastThresholdTime = now;

        // copy texture to buffer (full size, we sample later)
        const rowBytes = width * 4;
        const alignedBPR = Math.ceil(rowBytes / 256) * 256;
        const readBuffer = device.createBuffer({
          size: alignedBPR * height,
          usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ,
        });
        const copyEncoder = device.createCommandEncoder();
        copyEncoder.copyTextureToBuffer(
          { texture: resultTex },
          { buffer: readBuffer, bytesPerRow: alignedBPR },
          [width, height, 1],
        );
        device.queue.submit([copyEncoder.finish()]);

        await readBuffer.mapAsync(GPUMapMode.READ);
        const mapped = new Uint8Array(readBuffer.getMappedRange());
        const hist = new Uint32Array(256);
        // sample every `scale` pixels horizontally and vertically
        for (let y = 0; y < height; y += scale) {
          const rowStart = y * alignedBPR;
          for (let x = 0; x < width; x += scale) {
            hist[mapped[rowStart + x * 4]]++;
          }
        }
        readBuffer.unmap();
        readBuffer.destroy();

        // Otsu's method on smaller sample size
        let total = Math.ceil(height / scale) * Math.ceil(width / scale);
        let sum = 0;
        for (let i = 0; i < 256; i++) sum += i * hist[i];
        let sumB = 0,
          wB = 0,
          wF = 0;
        let varMax = 0,
          thresh = 0;
        for (let t = 0; t < 256; t++) {
          wB += hist[t];
          if (wB === 0) continue;
          wF = total - wB;
          if (wF === 0) break;
          sumB += t * hist[t];
          let mB = sumB / wB;
          let mF = (sum - sumB) / wF;
          let varBetween = wB * wF * (mB - mF) * (mB - mF);
          if (varBetween > varMax) {
            varMax = varBetween;
            thresh = t;
          }
        }
        // scale down Otsu result to make threshold brighter (more white pixels)
        threshold = Math.max(0, (thresh / 255) * 0.7);
        console.log(
          `Otsu thresh=${thresh}, normalized=${thresh / 255}, final=${threshold}`,
        );
      }

      function updateThresholdBuffer() {
        device.queue.writeBuffer(
          thresholdBuffer,
          0,
          new Float32Array([threshold]),
        );
      }

      function dispatch(pipeline, bindings) {
        const bindGroup = device.createBindGroup({
          layout: pipeline.getBindGroupLayout(0),
          entries: bindings,
        });

        const encoder = device.createCommandEncoder();
        const pass = encoder.beginComputePass();
        pass.setPipeline(pipeline);
        pass.setBindGroup(0, bindGroup);
        pass.dispatchWorkgroups(
          Math.ceil(width / WORKGROUP),
          Math.ceil(height / WORKGROUP),
        );
        pass.end();
        device.queue.submit([encoder.finish()]);
      }

      async function frame() {
        const videoTex = getVideoTexture();

        // Grayscale
        dispatch(grayscalePipeline, [
          { binding: 0, resource: videoTex },
          { binding: 1, resource: grayTex.createView() },
        ]);

        if (mode === "none") {
          render(grayTex);
          requestAnimationFrame(frame);
          return;
        }

        // Opening (common to white/black/threshold)
        dispatch(erosionPipeline, [
          { binding: 0, resource: grayTex.createView() },
          { binding: 1, resource: erodeTex.createView() },
        ]);

        dispatch(dilationPipeline, [
          { binding: 0, resource: erodeTex.createView() },
          { binding: 1, resource: dilateTex.createView() },
        ]);

        if (mode === "white" || thresholdOn) {
          dispatch(subtractPipeline, [
            { binding: 0, resource: grayTex.createView() },
            { binding: 1, resource: dilateTex.createView() },
            { binding: 2, resource: resultTex.createView() },
          ]);
        }

        if (mode === "black" || thresholdOn) {
          // black tophat path also writes into resultTex; if both white and black
          // were selected, the last one will win. thresholdOn will follow the
          // currently active tophat because mode holds it.
          if (mode === "black" || thresholdOn) {
            dispatch(dilationPipeline, [
              { binding: 0, resource: grayTex.createView() },
              { binding: 1, resource: tempTex.createView() },
            ]);

            dispatch(erosionPipeline, [
              { binding: 0, resource: tempTex.createView() },
              { binding: 1, resource: dilateTex.createView() },
            ]);

            dispatch(subtractPipeline, [
              { binding: 0, resource: dilateTex.createView() },
              { binding: 1, resource: grayTex.createView() },
              { binding: 2, resource: resultTex.createView() },
            ]);
          }
        }

        // if threshold toggle is active and a tophat mode is chosen, run
        // automatic thresholding on the resultTex and draw thresholdTex
        if (thresholdOn && mode !== "none") {
          if (thresholdDirty) {
            // compute using a coarse resolution (every 4th pixel) to speed up
            await computeAutoThreshold(4);
            updateThresholdBuffer();
            // update slider display to match automatic value
            const sVal = Math.round(threshold * 100);
            const sliderEl = document.getElementById("thresholdSlider");
            const valEl = document.getElementById("thresholdVal");
            if (sliderEl) sliderEl.value = sVal;
            if (valEl) valEl.textContent = sVal + "%";
            thresholdDirty = false;
          }

          dispatch(thresholdPipeline, [
            { binding: 0, resource: resultTex.createView() },
            { binding: 1, resource: thresholdTex.createView() },
            { binding: 2, resource: { buffer: thresholdBuffer } },
          ]);

          render(thresholdTex);
          requestAnimationFrame(frame);
          return;
        }

        // normal tophat result
        render(resultTex);
        requestAnimationFrame(frame);
      }

      function render(tex) {
        const view = context.getCurrentTexture().createView();

        const bindGroup = device.createBindGroup({
          layout: renderPipeline.getBindGroupLayout(0),
          entries: [
            { binding: 0, resource: tex.createView() },
            { binding: 1, resource: sampler },
          ],
        });

        const encoder = device.createCommandEncoder();
        const pass = encoder.beginRenderPass({
          colorAttachments: [
            {
              view,
              loadOp: "clear",
              storeOp: "store",
              clearValue: { r: 0, g: 0, b: 0, a: 1 },
            },
          ],
        });

        pass.setPipeline(renderPipeline);
        pass.setBindGroup(0, bindGroup);
        pass.draw(6);
        pass.end();

        device.queue.submit([encoder.finish()]);
      }

      document.getElementById("none").onclick = () => setMode("none");
      document.getElementById("white").onclick = () => setMode("white");
      document.getElementById("black").onclick = () => setMode("black");
      document.getElementById("threshold").onclick = () => toggleThreshold();

      // Threshold slider wiring: moving the slider sets manual threshold
      const thresholdSlider = document.getElementById("thresholdSlider");
      const thresholdVal = document.getElementById("thresholdVal");
      if (thresholdSlider) {
        thresholdSlider.addEventListener("input", (e) => {
          const v = Number(e.target.value || 0);
          threshold = v / 100;
          updateThresholdBuffer();
          thresholdOn = true;
          thresholdDirty = false;
          document.getElementById("threshold").classList.add("active");
          if (thresholdVal) thresholdVal.textContent = v + "%";
        });
        // initialize display
        thresholdSlider.value = Math.round(threshold * 100);
        if (thresholdVal)
          thresholdVal.textContent = Math.round(threshold * 100) + "%";
      }

      function setMode(m) {
        mode = m;
        thresholdDirty = true; // recompute if thresholding is active
        document
          .querySelectorAll("button")
          .forEach((b) => b.classList.remove("active"));
        document.getElementById(m).classList.add("active");
        if (thresholdOn) {
          document.getElementById("threshold").classList.add("active");
        }
      }

      function toggleThreshold() {
        thresholdOn = !thresholdOn;
        thresholdDirty = true;
        document
          .getElementById("threshold")
          .classList.toggle("active", thresholdOn);
      }

      requestAnimationFrame(frame);
    </script>
  </body>
</html>
